{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np \n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from scipy import linalg as LA\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading cleaned csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User i is data_1$[i]$ in the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = [0] * 57\n",
    "for i in range(len(data_1)):\n",
    "    fnames = glob.glob('labeled csv Geolife/'+str(i)+'/*.csv')\n",
    "    data_1[i] = np.array([np.loadtxt(f, delimiter=',')[1:] for f in fnames])\n",
    "data_1 = np.array(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3572"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = glob.glob('labeled csv Geolife/**/*.csv')\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users are stacked together in data_2 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = []\n",
    "fnames = glob.glob('labeled csv Geolife/**/*.csv')\n",
    "for f in fnames:\n",
    "    data_2.append(np.loadtxt(f, delimiter=',')[1:])\n",
    "data_2 = np.array(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 40392)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([len(data_2[i]) for i in range(len(data_2))])\n",
    "min(A), max(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing segments with length less than 1e-10 because of numerical precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3 = [0] * len(data_2)\n",
    "h = 1e-10\n",
    "c = 0\n",
    "for i in range(len(data_2)):\n",
    "    p1 = data_2[i][:-1]\n",
    "    p2 = data_2[i][1:]\n",
    "    L = ((p2[:,:2]-p1[:,:2])*(p2[:,:2]-p1[:,:2])).sum(axis =1)\n",
    "    I = np.where(L > h)[0]\n",
    "    J = np.where(L < h)[0]\n",
    "    if len(J) > 0:\n",
    "        c += 1\n",
    "    p1 = p1[I]\n",
    "    p2 = p2[I]\n",
    "    if len(I) == 0:\n",
    "        print(i)\n",
    "    gamma = np.concatenate((p1, p2[-1].reshape(1,4)), 0) \n",
    "    if len(gamma) > 0:\n",
    "        data_3[i] = gamma\n",
    "    data_3[i] = np.array(data_3[i])\n",
    "data_3 = np.array(data_3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 40323, array([1380]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([len(data_3[i]) for i in range(len(data_3))])\n",
    "min(A), max(A), np.where(A > 40000)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning trajectories to less than 20 minutes long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08333337376825511, 2085.283333301777, (array([2940]),))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 24 * 60 * (days_date('1899/12/30 2:50:06') - days_date('1899/12/30 2:20:06')) == 20 min\n",
    "Time = np.zeros(len(data_3))\n",
    "for i in range(len(data_3)):\n",
    "    Time[i] = 24 * 60 * sum(data_3[i][:,2][1:] - data_3[i][:,2][:-1]) # = 20 minutes \n",
    "min(Time), max(Time), np.where(Time>2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2365"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = np.where(Time>20)[0]\n",
    "len(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(trajectory):\n",
    "    trajectories = []\n",
    "    a = 24 * 60 * sum(trajectory[:,2][1:] - trajectory[:,2][:-1])\n",
    "    if a <= 20:\n",
    "        return np.array(trajectory.reshape(1, len(trajectory), 4))\n",
    "    else: \n",
    "        i = 0\n",
    "        while a > 20:\n",
    "            j = i + 0\n",
    "            val = 0\n",
    "            while val < 20: \n",
    "                if i < len(trajectory) - 1:\n",
    "                    temp = val + 0\n",
    "                    val += 24 * 60 * (trajectory[:,2][1:][i] - trajectory[:,2][:-1][i])\n",
    "                    i += 1\n",
    "                else: \n",
    "                    break\n",
    "            if len(trajectory[j:i-1]) > 0:\n",
    "                trajectories.append(trajectory[j:i-1])\n",
    "            a = a - val\n",
    "        if len(trajectory[i:]) > 0:\n",
    "            trajectories.append(trajectory[i:])\n",
    "    return trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if partitioning into less than 20 minutes worked correctly\n",
    "for j in J:\n",
    "    A = partition(data_3[j])\n",
    "    B = np.array([24 * 60 * sum(A[i][:,2][1:] - A[i][:,2][:-1]) for i in range(len(A))])\n",
    "    I = np.where(B > 20)[0]\n",
    "    if len(I) > 0: \n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_4 below is the array of trajectories having less than 20 minutes long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4 = []\n",
    "for i in range(len(data_3)):\n",
    "    A = partition(data_3[i])\n",
    "    for j in range(len(A)):\n",
    "        data_4.append(A[j])\n",
    "data_4 = np.array(data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11833,), (360, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4.shape, data_4[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11751"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = np.where(np.array([len(data_4[i]) for i in range(len(data_4))]) != 1)[0]\n",
    "data_4 = data_4[I]\n",
    "len(data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10039"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int1 = np.vectorize(int)\n",
    "data_5 = []\n",
    "c = 0\n",
    "for i in range(len(data_4)):\n",
    "    if len(set(int1(data_4[i][:,3]))) < 2: \n",
    "        data_5.append(data_4[i])\n",
    "        c += 1\n",
    "data_5 = np.array(data_5)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1671"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_6 = []\n",
    "d = 0\n",
    "for i in range(len(data_4)):\n",
    "    if len(set(int1(data_4[i][:,3]))) == 2: \n",
    "        data_6.append(data_4[i])\n",
    "        d += 1\n",
    "data_6 = np.array(data_6)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a:b\n",
    "# a is the number of labels in a trajectory\n",
    "# b is the number of trajectries with a labels\n",
    "D = {1:10121, 2:1671, 3:39, 4:2, 5:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modes = ['walk', 'bike', 'bus', 'driving', 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trajectories of length 1 with label 0, 1, 2, 3, 4: [3383, 1650, 1929, 2214, 863]\n"
     ]
    }
   ],
   "source": [
    "C = []\n",
    "for j in range(5):\n",
    "    c = 0\n",
    "    for i in range(len(data_5)):\n",
    "        if data_5[i][0][-1] == j:\n",
    "            c += 1\n",
    "    C.append(c)\n",
    "print(\"number of trajectories of length 1 with label 0, 1, 2, 3, 4:\", C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating trajectories with 3, 4, 5 labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing length 2 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1671, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_7 = [0] * len(data_6)\n",
    "for i in range(len(data_6)):\n",
    "    I = list(set(data_6[i][:,3]))\n",
    "    data_7[i] = []\n",
    "    J1 = np.where(data_6[i][:,3] == I[0])\n",
    "    J2 = np.where(data_6[i][:,3] == I[1])\n",
    "    D1 = data_6[i][J1]\n",
    "    D2 = data_6[i][J2]\n",
    "    data_7[i].append(D1)\n",
    "    data_7[i].append(D2)\n",
    "data_7 = np.array(data_7)\n",
    "data_7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating sentences of length 3, 4, 5 from 10039 length 1 trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "n_1 = 1000 # number of length 1 sentences\n",
    "n_2 = 1000 # len(data_7)# 1671: number of length 2 sentences\n",
    "n_3 = 800 # number of length 3 sentences\n",
    "n_4 = 700 # number of length 4 sentences\n",
    "n_5 = 1900 # number of length 5 sentences\n",
    "\n",
    "for i in range(n_1):\n",
    "    I = np.random.randint(0, 10039, size=1)\n",
    "    data.append(data_5[I])\n",
    "    \n",
    "for i in range(n_2): \n",
    "    data.append(data_7[i])\n",
    "\n",
    "for i in range(n_3):\n",
    "    I = np.random.randint(0, 10039, size=3)\n",
    "    data.append(data_5[I])\n",
    "\n",
    "for i in range(n_4):\n",
    "    I = np.random.randint(0, 10039, size=4)\n",
    "    data.append(data_5[I])\n",
    "    \n",
    "for i in range(n_5):\n",
    "    I = np.random.randint(0, 10039, size=5)\n",
    "    data.append(data_5[I])\n",
    "    \n",
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,) (2,) (3,) (4,) (5,)\n"
     ]
    }
   ],
   "source": [
    "print(data[0].shape, data[n_1].shape, data[n_1+n_2].shape, data[n_1+n_2+n_3].shape, \n",
    "      data[n_1+n_2+n_3+n_4].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions needed for CMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/x-python"
   },
   "source": [
    "$x = (x_1, x_2, \\ldots, x_n)$\n",
    "\n",
    "$y = (y_1, y_2, \\ldots, y_n) \\in \\{0,1,2,3,4\\}^n$\n",
    "\n",
    "If $x_i = [(a_0, b_0, t_0), \\ldots, (a_m, b_m, t_m)]$, where $a_j$ is latitude, $b_j$ is longitude and $t_j$ is time, then \n",
    "$$\\displaystyle \\text{length}_i = \\frac{1}{m} \\sum_{j=1}^m \\|(a_j, b_j) - (a_{j-1}, b_{j-1})\\|_2,$$\n",
    "$$\\text{velocity}_i = \\frac{1}{m} \\sum_{j=1}^m \\frac{\\|(a_j, b_j) - (a_{j-1}, b_{j-1})\\|_2}{t_j},$$\n",
    "$$\\text{acceleration}_i = \\frac{1}{m} \\sum_{j=1}^m \\frac{\\|(a_j, b_j) - (a_{j-1}, b_{j-1})\\|_2}{t_j^2}.$$\n",
    "\n",
    "#Notice: I have divded the acceleration by 1e10 for all data. \n",
    "\n",
    "### $\\phi_1(x, y) = (\\text{length}_i, \\text{velocity}_i, \\text{acceleration}_i, y_i)_{i=1}^n \\in \\mathbb{R}^{4n}$\n",
    "\n",
    "### $\\phi_2(x, y) = (\\text{start point}_i, \\text{end point}_i, \\text{length}_i, \\text{velocity}_i, \\text{acceleration}_i, y_i)_{i=1}^n \\in \\mathbb{R}^{8n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Mapping $\\phi_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMapping1(data):\n",
    "    Data = [0] * len(data)\n",
    "    for i in range(len(data)):\n",
    "        Data[i] = []\n",
    "        for j in range(len(data[i])):\n",
    "            D = data[i][j]\n",
    "            segments = D[:,:2][1:] - D[:,:2][:-1]\n",
    "            segments_lengths = np.sqrt(np.sum((segments)**2, 1))\n",
    "            I = np.where(segments_lengths > 1e-8)\n",
    "            D = D[I]\n",
    "            if len(D) > 1:\n",
    "                segments = D[:,:2][1:] - D[:,:2][:-1]\n",
    "                segments_lengths = np.sqrt(np.sum((segments)**2, 1))\n",
    "                length = np.sum(segments_lengths)/len(D) + 1e-10\n",
    "                time = D[:,2][1:] - D[:,2][:-1] + 1e-10\n",
    "                velocities = segments_lengths/time\n",
    "                velocity = np.mean(velocities)\n",
    "                accelerations = segments_lengths/time**2\n",
    "                acceleration = np.mean(accelerations)/1e10\n",
    "                y = D[0][-1]\n",
    "                array = np.array([length, velocity, acceleration, y])\n",
    "                Data[i].append(array)\n",
    "        Data[i] = np.array(Data[i])\n",
    "\n",
    "    Data = np.array(Data)\n",
    "    K = np.array([len(Data[i]) for i in range(len(Data))])\n",
    "    J = np.where(K > 0)\n",
    "    Data = Data[J]\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Mapping $\\phi_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMapping2(data):\n",
    "    Data = [0] * len(data)\n",
    "    for i in range(len(data)):\n",
    "        Data[i] = []\n",
    "        for j in range(len(data[i])):\n",
    "            D = data[i][j]\n",
    "            segments = D[:,:2][1:] - D[:,:2][:-1]\n",
    "            segments_lengths = np.sqrt(np.sum((segments)**2, 1))\n",
    "            I = np.where(segments_lengths > 1e-8)\n",
    "            D = D[I]\n",
    "            if len(D) > 1:\n",
    "                segments = D[:,:2][1:] - D[:,:2][:-1]\n",
    "                segments_lengths = np.sqrt(np.sum((segments)**2, 1))\n",
    "                length = np.sum(segments_lengths)/len(D) + 1e-10\n",
    "                time = D[:,2][1:] - D[:,2][:-1] + 1e-10\n",
    "                velocities = segments_lengths/time\n",
    "                velocity = np.mean(velocities)\n",
    "                accelerations = segments_lengths/time**2\n",
    "                acceleration = np.mean(accelerations)/1e10\n",
    "                y = D[0][-1]\n",
    "                array = np.array([length, velocity, acceleration, \n",
    "                                  D[0][0], D[0][1], D[-1][0], D[-1][1], y])\n",
    "                Data[i].append(array)\n",
    "        Data[i] = np.array(Data[i])\n",
    "\n",
    "    Data = np.array(Data)\n",
    "    K = np.array([len(Data[i]) for i in range(len(Data))])\n",
    "    J = np.where(K > 0)\n",
    "    Data = Data[J]\n",
    "    return(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature mapping using landmarks\n",
    "\n",
    "$x = (x_1, x_2, \\ldots, x_n)$\n",
    "\n",
    "$y = (y_1, y_2, \\ldots, y_n) \\in \\{0,1,2,3,4\\}^n$\n",
    "\n",
    "If $x_i = [(a_0, b_0, t_0), \\ldots, (a_m, b_m, t_m)]$, where $a_j$ is latitude, $b_j$ is longitude and $t_j$ is time, then \n",
    "$$\\displaystyle \\text{length}_i = \\frac{1}{m} \\sum_{j=1}^m \\|(a_j, b_j) - (a_{j-1}, b_{j-1})\\|_2,$$\n",
    "$$\\text{velocity}_i = \\frac{1}{m} \\sum_{j=1}^m \\frac{\\|(a_j, b_j) - (a_{j-1}, b_{j-1})\\|_2}{t_j},$$\n",
    "$$\\text{acceleration}_i = \\frac{1}{m} \\sum_{j=1}^m \\frac{\\|(a_j, b_j) - (a_{j-1}, b_{j-1})\\|_2}{t_j^2}.$$\n",
    "\n",
    "#Notice: I have divded the acceleration by 1e10 for all data. \n",
    "\n",
    "#### Now we would like to use a feature mapping introduced in the following paper:\n",
    "\n",
    "``Jeff M. Phillips and Pingfan Tang. Simple distances for trajectories via landmarks. In ACM GIS SIGSPATIAL, 2019.''\n",
    "\n",
    "Following the paper, let $q \\in \\mathbb{R}^2$ be a landmark and $\\gamma$ be a trajectory in $\\mathbb{R}^2$. We define \n",
    "$$v_q(\\gamma) = {\\rm dist}(\\gamma, q) = min_{p \\in \\gamma} \\|q - p\\|_2.$$\n",
    "\n",
    "We randomly choose $m$ (here $m=20$ will be used) landmaks in $\\mathbb{R}^2$ around trajectories and call them $Q$, so $Q=\\{q_1, q_2, \\ldots, q_m\\}$. Then we define the feature mapping $v_Q$ by \n",
    "$$v_Q(\\gamma) = (v_{q_1}(\\gamma), v_{q_2}(\\gamma), \\ldots, v_{q_m}(\\gamma)) \\in \\mathbb{R}^m.$$\n",
    "\n",
    "Then we combine this feature mapping with $\\phi_1$ and $\\phi_2$ to get the following feature mappings:\n",
    "\n",
    "### $\\phi_3(x, y) = (v_Q(x_i), y_i)_{i=1}^n \\in \\mathbb{R}^{(m+1)n}$\n",
    "\n",
    "### $\\phi_4(x, y) = (v_Q(x_i), \\text{length}_i, \\text{velocity}_i, \\text{acceleration}_i, y_i)_{i=1}^n \\in \\mathbb{R}^{(m+4)n}$\n",
    "\n",
    "### $\\phi_5(x, y) = (v_Q(x_i), \\text{start point}_i, \\text{end point}_i, \\text{length}_i, \\text{velocity}_i, \\text{acceleration}_i, y_i)_{i=1}^n \\in \\mathbb{R}^{(m+8)n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landmark Feature Mapping $v_Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMap_v_Q(Q, gamma):\n",
    "    \n",
    "    p2 = gamma[1:]\n",
    "    p1 = gamma[:-1]\n",
    "    L = np.sqrt(((p2-p1)*(p2-p1)).sum(axis =1))\n",
    "    II = np.where(L>10e-8)[0]\n",
    "    L = L[II]\n",
    "    p1 = p1[II]\n",
    "    p2 = p2[II]\n",
    "    w = (p1-p2)*(-1,1)/(L*np.ones((2,1))).T\n",
    "    w[:,[0, 1]] = w[:,[1, 0]]\n",
    "    \n",
    "    dist_dot = np.sum(w * (Q.reshape(len(Q),1,2) - p1), axis=2)\n",
    "    \n",
    "    x = abs(dist_dot.copy())\n",
    "    R = (L**2).reshape(-1,1)\n",
    "    u = p1 + ((((np.sum(((Q.reshape(len(Q),1,2) - p1) * (p2 - p1)),axis=2).reshape(len(Q)\n",
    "                ,-1,1,1) * (p2-p1).reshape(len(p2-p1),1,2))).reshape(len(Q),len(p1),2))/R)\n",
    "    \n",
    "    G = np.sqrt(np.sum((u-p1)*(u-p1), axis=2))\n",
    "    H = np.sqrt(np.sum((u-p2)*(u-p2), axis=2))\n",
    "    d1 = np.sqrt(np.sum((Q.reshape(len(Q),1,2)-p1)*(Q.reshape(len(Q),1,2)-p1), axis=2))\n",
    "    d2 = np.sqrt(np.sum((Q.reshape(len(Q),1,2)-p2)*(Q.reshape(len(Q),1,2)-p2), axis=2))\n",
    "\n",
    "    dist = np.where(abs(G + H - L) < np.ones(len(L)) * (10e-8), x, np.minimum(d1, d2))\n",
    "\n",
    "    j = np.argmin(dist, axis =1)\n",
    "    dist_weighted = dist[np.arange(len(dist)),j]\n",
    "    \n",
    "    return dist_weighted.reshape(len(Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeatureMapping3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMapping3(data, Q):\n",
    "    Data = [0] * len(data)\n",
    "    for i in range(len(data)):\n",
    "        Data[i] = []\n",
    "        for j in range(len(data[i])):\n",
    "            D = data[i][j]\n",
    "            segments = D[:,:2][1:] - D[:,:2][:-1]\n",
    "            segments_lengths = np.sqrt(np.sum((segments)**2, 1))\n",
    "            I = np.where(segments_lengths > 1e-8)\n",
    "            D = D[I]\n",
    "            if len(D) > 1:\n",
    "                segments = D[:,:2][1:] - D[:,:2][:-1]\n",
    "                segments_lengths = np.sqrt(np.sum((segments)**2, 1))\n",
    "                length = np.sum(segments_lengths)/len(D) + 1e-10\n",
    "                time = D[:,2][1:] - D[:,2][:-1] + 1e-10\n",
    "                velocities = segments_lengths/time\n",
    "                velocity = np.mean(velocities)\n",
    "                accelerations = segments_lengths/time**2\n",
    "                acceleration = np.mean(accelerations)/1e10\n",
    "                y = D[0][-1]\n",
    "                array_vel_acc = np.array([y])\n",
    "                mapped_v_Q_D = featureMap_v_Q(Q, D[:,:2])\n",
    "                array = np.concatenate((mapped_v_Q_D, array_vel_acc), 0)\n",
    "                Data[i].append(array)\n",
    "        Data[i] = np.array(Data[i])\n",
    "\n",
    "    Data = np.array(Data)\n",
    "    K = np.array([len(Data[i]) for i in range(len(Data))])\n",
    "    J = np.where(K > 0)\n",
    "    Data = Data[J]\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature mapping composed of $v_Q$ and featureMapping1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMapping4(data, Q):\n",
    "    Data = [0] * len(data)\n",
    "    for i in range(len(data)):\n",
    "        Data[i] = []\n",
    "        for j in range(len(data[i])):\n",
    "            D = data[i][j]\n",
    "            segments = D[:,:2][1:] - D[:,:2][:-1]\n",
    "            segments_lengths = np.sqrt(np.sum((segments)**2, 1))\n",
    "            I = np.where(segments_lengths > 1e-8)\n",
    "            D = D[I]\n",
    "            if len(D) > 1:\n",
    "                segments = D[:,:2][1:] - D[:,:2][:-1]\n",
    "                segments_lengths = np.sqrt(np.sum((segments)**2, 1))\n",
    "                length = np.sum(segments_lengths)/len(D) + 1e-10\n",
    "                time = D[:,2][1:] - D[:,2][:-1] + 1e-10\n",
    "                velocities = segments_lengths/time\n",
    "                velocity = np.mean(velocities)\n",
    "                accelerations = segments_lengths/time**2\n",
    "                acceleration = np.mean(accelerations)/1e10\n",
    "                y = D[0][-1]\n",
    "                array_vel_acc = np.array([length, velocity, acceleration, y])\n",
    "                mapped_v_Q_D = featureMap_v_Q(Q, D[:,:2])\n",
    "                array = np.concatenate((mapped_v_Q_D, array_vel_acc), 0)\n",
    "                Data[i].append(array)\n",
    "        Data[i] = np.array(Data[i])\n",
    "\n",
    "    Data = np.array(Data)\n",
    "    K = np.array([len(Data[i]) for i in range(len(Data))])\n",
    "    J = np.where(K > 0)\n",
    "    Data = Data[J]\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature mapping composed of $v_Q$ and featureMapping2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMapping5(data, Q):\n",
    "    Data = [0] * len(data)\n",
    "    for i in range(len(data)):\n",
    "        Data[i] = []\n",
    "        for j in range(len(data[i])):\n",
    "            D = data[i][j]\n",
    "            segments = D[:,:2][1:] - D[:,:2][:-1]\n",
    "            segments_lengths = np.sqrt(np.sum((segments)**2, 1))\n",
    "            I = np.where(segments_lengths > 1e-8)\n",
    "            D = D[I]\n",
    "            if len(D) > 1:\n",
    "                segments = D[:,:2][1:] - D[:,:2][:-1]\n",
    "                segments_lengths = np.sqrt(np.sum((segments)**2, 1))\n",
    "                length = np.sum(segments_lengths)/len(D) + 1e-10\n",
    "                time = D[:,2][1:] - D[:,2][:-1] + 1e-10\n",
    "                velocities = segments_lengths/time\n",
    "                velocity = np.mean(velocities)\n",
    "                accelerations = segments_lengths/time**2\n",
    "                acceleration = np.mean(accelerations)/1e10\n",
    "                y = D[0][-1]\n",
    "                array_vel_acc = np.array([length, velocity, acceleration, \n",
    "                                  D[0][0], D[0][1], D[-1][0], D[-1][1], y])\n",
    "                mapped_v_Q_D = featureMap_v_Q(Q, D[:,:2])\n",
    "                array = np.concatenate((mapped_v_Q_D, array_vel_acc), 0)\n",
    "                Data[i].append(array)\n",
    "        Data[i] = np.array(Data[i])\n",
    "\n",
    "    Data = np.array(Data)\n",
    "    K = np.array([len(Data[i]) for i in range(len(Data))])\n",
    "    J = np.where(K > 0)\n",
    "    Data = Data[J]\n",
    "    return(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestSplit(data):\n",
    "    k = 5 # 80/20 train/test split\n",
    "    I = []\n",
    "    random.shuffle(data)\n",
    "    for j in range(1,6):\n",
    "        I.append(np.where([len(data[i])==j for i in range(len(Data))])[0])\n",
    "\n",
    "    train = np.concatenate((data[I[0]][len(I[0])//k:], data[I[1]][len(I[1])//k:], \n",
    "                            data[I[2]][len(I[2])//k:], data[I[3]][len(I[3])//k:], \n",
    "                            data[I[4]][len(I[4])//k:]), 0)\n",
    "\n",
    "    test = np.concatenate((data[I[0]][:len(I[0])//k], data[I[1]][:len(I[1])//k],\n",
    "                           data[I[2]][:len(I[2])//k], data[I[3]][:len(I[3])//k],\n",
    "                           data[I[4]][:len(I[4])//k]), 0)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for feeding to a clsaaifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localModel(data):\n",
    "    X = [0] * 5 # 5 is the length of label set\n",
    "    X[0] = []\n",
    "    for i in range(len(data)):\n",
    "        X[0].append(data[i][0])\n",
    "    X[0] = np.array(X[0])\n",
    "    for j in range(1, 5):\n",
    "        X[j] = []\n",
    "        I = np.where([len(data[i]) > j for i in range(len(data))])[0]\n",
    "        for i in I:\n",
    "            X[j].append(np.insert(data[i][j], len(data[i][j])-1, data[i][j-1][-1], axis=0))\n",
    "        X[j] = np.array(X[j])\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRF(X, num_estimators = 100):\n",
    "    \n",
    "    clf = [0] * 5\n",
    "    accuracies = np.zeros(len(X))\n",
    "\n",
    "    for i in range(len(X)): \n",
    "        clf[i] = RandomForestClassifier(n_estimators=num_estimators, criterion='gini', \n",
    "                       max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "                       min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                       max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                       min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "                       n_jobs=None, random_state=None, verbose=0, \n",
    "                       warm_start=False, class_weight=None, ccp_alpha=0.0, \n",
    "                       max_samples=None)\n",
    "\n",
    "        clf[i].fit(X[i][:,:-1], X[i][:, -1])\n",
    "        X_pred = clf[i].predict(X[i][:, :-1])\n",
    "        accuracies[i] = metrics.accuracy_score(X[i][:, -1], X_pred)\n",
    "        \n",
    "    print(\"train accuracies for local classifiers given x_i and y_{i-1} =\") \n",
    "    print(accuracies)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get scores by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreRF(data, clf):\n",
    "    scores = [0] * len(data)\n",
    "    S_0 = clf[0].predict_proba(data[0][:-1].reshape(1, len(data[0])-1))[0]\n",
    "    S_0_arg_added = np.concatenate((-np.ones(5).reshape(-1,1), S_0.reshape(-1,1)), 1)\n",
    "    scores[0] = S_0_arg_added\n",
    "    for i in range(1, len(data)):\n",
    "        S = np.zeros((5,5))\n",
    "        for k in range(5):\n",
    "            a = clf[i].predict_proba(np.insert(data[i][:-1], len(data[i])-1,\n",
    "                                                k, axis=0).reshape(1, len(data[i])))[0]\n",
    "            S[:,k] = a + scores[i-1][:,1][k]\n",
    "        scores[i] = np.concatenate((np.argmax(S,1).reshape(-1,1), \n",
    "                                    np.max(S,1).reshape(-1,1)) ,1)\n",
    "    scores = np.array(scores)\n",
    "    return scores\n",
    "\n",
    "def scoresRF(data, clf):\n",
    "    scores = [0] * len(data)\n",
    "    for i in range(len(data)):\n",
    "        scores[i] = scoreDT_RF(data[i], clf)\n",
    "    scores = np.array(scores)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi algorithm (in order to find argmaxs i.e., labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictViterbiRF(data, clf):\n",
    "    scores = scoresRF(data, clf)\n",
    "    y_pred = [0] * len(data)\n",
    "    for j in range(len(data)):\n",
    "        if len(data[j]) > 1:\n",
    "            y_pred[j] = np.zeros(len(data[j]))\n",
    "            b = int(np.argmax(scores[j][-1][:,1]))\n",
    "            y_pred[j][-1] = b\n",
    "            for i in range(len(data[j])-1, 0, -1):\n",
    "                b = int(scores[j][i][b][0])\n",
    "                y_pred[j][i-1] = b\n",
    "        elif len(data[j]) == 1:\n",
    "            y_pred[j] = np.zeros(len(data[j]))\n",
    "            y_pred[j][0] = int(np.argmax(scores[j][-1][:,1]))\n",
    "\n",
    "    accuracies = np.zeros(len(data))\n",
    "    for i in range(len(data)):\n",
    "        accuracies[i] = metrics.accuracy_score(y_pred[i], data[i][:,-1])\n",
    "    accuracy = np.mean(accuracies)\n",
    "    return y_pred, accuracy, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience with feature mapping $\\phi_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = featureMapping1(data)\n",
    "train, test = trainTestSplit(Data)\n",
    "X = localModel(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracies for local classifiers given x_i and y_{i-1} =\n",
      "[0.97035665 1.         1.         1.         1.        ]\n",
      "train accuracy = 0.9894897329010345\n",
      "test accuracy = 0.7480810894459919\n"
     ]
    }
   ],
   "source": [
    "clfRF = trainRF(X, 100)\n",
    "print(\"train accuracy =\", predictViterbiDT_RF(train, clfRF)[1])\n",
    "print(\"test accuracy =\", predictViterbiDT_RF(test, clfRF)[1]) # 0.7310492107706592"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience with feature mapping $\\phi_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = featureMapping2(data)\n",
    "train, test = trainTestSplit(Data)\n",
    "X = localModel(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracies for local classifiers given x_i and y_{i-1} =\n",
      "[1. 1. 1. 1. 1.]\n",
      "train accuracy = 1.0\n",
      "test accuracy = 0.8356081708449397\n"
     ]
    }
   ],
   "source": [
    "clfRF = trainRF(X, 100)\n",
    "print(\"train accuracy =\", predictViterbiDT_RF(train, clfRF)[1])\n",
    "print(\"test accuracy =\", predictViterbiDT_RF(test, clfRF)[1]) # 0.8184659617881654 (66/33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience with feature mapping $v_Q$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, c = np.min([np.min([np.min(data[i][j][:,:2], axis=0) for j in range(len(data[i]))], \n",
    "                      axis=0) for i in range(len(data))], axis=0)\n",
    "  \n",
    "b, d = np.max([np.max([np.max(data[i][j][:,:2], axis=0) for j in range(len(data[i]))], \n",
    "                      axis=0) for i in range(len(data))], axis=0)\n",
    "\n",
    "Mean = np.mean([np.mean([np.mean(data[i][k][:,:2], axis=0) for k in range(len(data[i]))], \n",
    "                      axis=0) for i in range(len(data))], axis=0)\n",
    "\n",
    "Std = np.std([np.std([np.std(data[i][l][:,:2], axis=0) for l in range(len(data[i]))], \n",
    "                      axis=0) for i in range(len(data))], axis=0)\n",
    "\n",
    "m = 50\n",
    "Q = np.ones((m,2))\n",
    "\n",
    "Q[:20,0] = np.random.normal(Mean[0], 100*Std[0], 20)\n",
    "Q[:20,1] = np.random.normal(Mean[1], 20*Std[1], 20) \n",
    "\n",
    "Q[20:30,0] = np.random.normal(Mean[0], 10*Std[0], 10)\n",
    "Q[20:30,1] = np.random.normal(Mean[1], 2*Std[1], 10) \n",
    "\n",
    "Q[30:40,0] = np.random.normal(Mean[0], 200*Std[0], 10)\n",
    "Q[30:40,1] = np.random.normal(Mean[1], 50*Std[1], 10) \n",
    "\n",
    "Q[40:50,0] = np.random.normal(Mean[0], 100*Std[0], 10)\n",
    "Q[40:50,1] = np.random.normal(Mean[1], 200*Std[1], 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 39.01456032, 114.41938697],\n",
       "       [ 44.60402289, 114.49902951],\n",
       "       [ 59.74421979, 114.80187404],\n",
       "       [ 43.1037752 , 114.34228763],\n",
       "       [ 38.7122953 , 114.76786571],\n",
       "       [ 28.64863586, 114.3902571 ],\n",
       "       [ 39.20164582, 114.59714934],\n",
       "       [ 43.83791521, 114.55153728],\n",
       "       [ 51.95232759, 114.52629161],\n",
       "       [ 45.20844743, 114.34747072],\n",
       "       [ 39.35727746, 114.55966056],\n",
       "       [ 43.98305791, 114.49071965],\n",
       "       [ 42.85731024, 114.32181564],\n",
       "       [ 45.48539274, 114.44486893],\n",
       "       [ 44.13633837, 114.42477996],\n",
       "       [ 38.3255302 , 114.79699519],\n",
       "       [ 36.01313788, 114.41540206],\n",
       "       [ 40.88310718, 114.61261736],\n",
       "       [ 34.85392938, 115.26580424],\n",
       "       [ 40.19032122, 114.79584792],\n",
       "       [ 41.18103307, 114.57728672],\n",
       "       [ 39.47667869, 114.58460655],\n",
       "       [ 39.32368725, 114.60485901],\n",
       "       [ 39.79508647, 114.59673084],\n",
       "       [ 39.52803937, 114.5776205 ],\n",
       "       [ 39.86744632, 114.62498803],\n",
       "       [ 39.32795086, 114.58302694],\n",
       "       [ 40.20458001, 114.60418528],\n",
       "       [ 40.29808186, 114.57092493],\n",
       "       [ 39.21478607, 114.59779533],\n",
       "       [ 38.22682814, 114.64892699],\n",
       "       [ 45.06872168, 114.18942796],\n",
       "       [ 41.00913609, 114.42903674],\n",
       "       [ 53.94085021, 113.85525888],\n",
       "       [ 22.52952292, 114.39203386],\n",
       "       [ 40.20174496, 114.49618779],\n",
       "       [ 39.84360045, 115.07438854],\n",
       "       [ 49.89980587, 115.32611845],\n",
       "       [ 37.50464323, 114.52486221],\n",
       "       [ 26.60054502, 115.03735523],\n",
       "       [ 35.15093362, 116.11584761],\n",
       "       [ 23.31689907, 116.40054604],\n",
       "       [ 43.73234314, 117.23850613],\n",
       "       [ 38.06776806, 113.6049842 ],\n",
       "       [ 35.33189297, 112.31679572],\n",
       "       [ 46.3344954 , 116.36609094],\n",
       "       [ 54.65658249, 112.56189262],\n",
       "       [ 55.10367492, 116.10983259],\n",
       "       [ 26.2040827 , 113.86314561],\n",
       "       [ 26.75218225, 116.24911084]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    plt.plot(data[i][0][:,0], data[i][0][:,1]);\n",
    "\n",
    "plt.scatter(Q[:,0], Q[:,1], s = 10, color = \"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience with feature mapping $\\phi_3 = v_Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = featureMapping3(data, Q)\n",
    "train, test = trainTestSplit(Data)\n",
    "X = localModel(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracies for local classifiers given x_i and y_{i-1} =\n",
      "[1. 1. 1. 1. 1.]\n",
      "train accuracy = 1.0\n",
      "test accuracy = 0.7832714329928815\n"
     ]
    }
   ],
   "source": [
    "clfRF = trainRF(X, 100)\n",
    "print(\"train accuracy =\", predictViterbiDT_RF(train, clfRF)[1])\n",
    "print(\"test accuracy =\", predictViterbiDT_RF(test, clfRF)[1]) # 0.7643665368206269 (66/33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience with feature mapping $\\phi_4 = v_Q$ + $\\phi_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = featureMapping4(data, Q[:20])\n",
    "train, test = trainTestSplit(Data)\n",
    "X = localModel(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracies for local classifiers given x_i and y_{i-1} =\n",
      "[1. 1. 1. 1. 1.]\n",
      "train accuracy = 1.0\n",
      "test accuracy = 0.8499380996595481\n"
     ]
    }
   ],
   "source": [
    "clfRF = trainRF(X, 80)\n",
    "print(\"train accuracy =\", predictViterbiDT_RF(train, clfRF)[1])\n",
    "print(\"test accuracy =\", predictViterbiDT_RF(test, clfRF)[1]) # 0.8289371174179188 (66/33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience with feature mapping $\\phi_5 = v_Q$ + $\\phi_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = featureMapping5(data, Q)\n",
    "train, test = trainTestSplit(Data)\n",
    "X = localModel(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracies for local classifiers given x_i and y_{i-1} =\n",
      "[1. 1. 1. 1. 1.]\n",
      "train accuracy = 1.0\n",
      "test accuracy = 0.8479727638502011\n"
     ]
    }
   ],
   "source": [
    "clfRF = trainRF(X, 120)\n",
    "print(\"train accuracy =\", predictViterbiDT_RF(train, clfRF)[1])\n",
    "print(\"test accuracy =\", predictViterbiDT_RF(test, clfRF)[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
